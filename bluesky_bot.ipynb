{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atproto import Client\n",
    "import pandas as pd\n",
    "from pyzotero import zotero\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from typing import List, Dict\n",
    "from bs4 import BeautifulSoup\n",
    "from grapheme import length as grapheme_length\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProfileViewDetailed(did='did:plc:i3ybq75q7rbcxzrzl2d6jy7c', handle='intelbase.bsky.social', associated=ProfileAssociated(chat=ProfileAssociatedChat(allow_incoming='following', py_type='app.bsky.actor.defs#profileAssociatedChat'), feedgens=0, labeler=False, lists=0, starter_packs=0, py_type='app.bsky.actor.defs#profileAssociated'), avatar='https://cdn.bsky.app/img/avatar/plain/did:plc:i3ybq75q7rbcxzrzl2d6jy7c/bafkreiakobz3zg3dmdpujbnjvb6fpb3wxh3mvd4s77mtgwwsy35gzfvfly@jpeg', banner=None, created_at='2024-08-15T22:38:10.586Z', description=None, display_name='', followers_count=0, follows_count=1, indexed_at='2024-08-15T22:38:10.586Z', joined_via_starter_pack=None, labels=[], posts_count=1, viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by=None, following=None, known_followers=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewDetailed')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(base_url='https://bsky.social')\n",
    "client.login('intelbase.bsky.social', '34GBRimperialTW905*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_content = 'Check out my profile: https://bsky.app/profile/intelbase.bsky.social'\n",
    "\n",
    "\n",
    "# post = client.send_post(post_content)\n",
    "\n",
    "# def mark_urls(text):\n",
    "#     import re\n",
    "    \n",
    "#     # Define the regex pattern for URLs\n",
    "#     regex = r'(https?://[^\\s]+)'\n",
    "#     matches = re.finditer(regex, text)\n",
    "    \n",
    "#     url_data = []\n",
    "    \n",
    "#     # Find all matches and store their positions and URLs\n",
    "#     for match in matches:\n",
    "#         url = match.group(0)\n",
    "#         start = match.start()\n",
    "#         end = match.end()\n",
    "        \n",
    "#         url_data.append({\n",
    "#             'start': start,\n",
    "#             'end': end,\n",
    "#             'url': url,\n",
    "#         })\n",
    "    \n",
    "#     return url_data\n",
    "\n",
    "\n",
    "# # Post content\n",
    "# post_content = 'Check out my profile: https://bsky.app/profile/intelbase.bsky.social'\n",
    "\n",
    "# # Parse URLs to get their positions\n",
    "# urls = mark_urls(post_content)\n",
    "\n",
    "# # Create the facets for the link\n",
    "# facets = []\n",
    "# for url in urls:\n",
    "#     facets.append({\n",
    "#         \"index\": {\n",
    "#             \"byteStart\": url['start'],\n",
    "#             \"byteEnd\": url['end']\n",
    "#         },\n",
    "#         \"features\": [\n",
    "#             {\n",
    "#                 \"$type\": \"app.bsky.richtext.facet#link\",\n",
    "#                 \"uri\": url['url']\n",
    "#             }\n",
    "#         ]\n",
    "#     })\n",
    "\n",
    "# # Send post with text and facets\n",
    "# post = client.send_post(\n",
    "#     text=post_content,\n",
    "#     facets=facets,\n",
    "#     langs=['en']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication type</th>\n",
       "      <th>Link to publication</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Zotero link</th>\n",
       "      <th>Date added</th>\n",
       "      <th>Date published</th>\n",
       "      <th>Date modified</th>\n",
       "      <th>Col key</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Pub_venue</th>\n",
       "      <th>Book_title</th>\n",
       "      <th>Thesis_type</th>\n",
       "      <th>University</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Global To National Views: Examining Intel...</td>\n",
       "      <td>Journal article</td>\n",
       "      <td>https://jjoas.com.ng/2024/01/25/from-global-to...</td>\n",
       "      <td>No abstract</td>\n",
       "      <td>https://www.zotero.org/groups/intelligence_bib...</td>\n",
       "      <td>2024-08-16 00:11:00+00:00</td>\n",
       "      <td>25-01-2024</td>\n",
       "      <td>16/08/2024, 00:12</td>\n",
       "      <td>[TLFN4NAL]</td>\n",
       "      <td>Adebimpe S. Fagbemi</td>\n",
       "      <td>Jalingo Journal of African Studies</td>\n",
       "      <td>None</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td></td>\n",
       "      <td>TLFN4NAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intelligence Studies Network dataset</td>\n",
       "      <td>Dataset</td>\n",
       "      <td>https://zenodo.org/records/13325699</td>\n",
       "      <td>This dataset contains metadata of publications...</td>\n",
       "      <td>https://www.zotero.org/groups/intelligence_bib...</td>\n",
       "      <td>2024-08-15 11:06:38+00:00</td>\n",
       "      <td>15-08-2024</td>\n",
       "      <td>15/08/2024, 11:06</td>\n",
       "      <td>[CN9F5URY]</td>\n",
       "      <td>Yusuf A. Ozkan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td></td>\n",
       "      <td>CN9F5URY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intelligence, Security and the State: Reviewin...</td>\n",
       "      <td>Book</td>\n",
       "      <td>https://edinburghuniversitypress.com/book-inte...</td>\n",
       "      <td>The modern-day UK intelligence and security co...</td>\n",
       "      <td>https://www.zotero.org/groups/intelligence_bib...</td>\n",
       "      <td>2024-08-14 21:02:35+00:00</td>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>14/08/2024, 21:03</td>\n",
       "      <td>[CK5MNYPQ]</td>\n",
       "      <td>Daniel W. B. Lomas, Christopher J. Murphy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td></td>\n",
       "      <td>CK5MNYPQ</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“A Spy Thriller Outdoes Fiction”: Popular Cult...</td>\n",
       "      <td>Journal article</td>\n",
       "      <td>https://www.tandfonline.com/doi/abs/10.1080/14...</td>\n",
       "      <td>Scholars are increasingly aware of the ways in...</td>\n",
       "      <td>https://www.zotero.org/groups/intelligence_bib...</td>\n",
       "      <td>2024-08-14 21:01:32+00:00</td>\n",
       "      <td>13-08-2024</td>\n",
       "      <td>14/08/2024, 21:01</td>\n",
       "      <td>[CZT6L9T7, 9YH9YSYQ]</td>\n",
       "      <td>Melanie Brand</td>\n",
       "      <td>Journal of Australian Studies</td>\n",
       "      <td>None</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td></td>\n",
       "      <td>CZT6L9T7</td>\n",
       "      <td>9YH9YSYQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Publication type  \\\n",
       "0  From Global To National Views: Examining Intel...  Journal article   \n",
       "1               Intelligence Studies Network dataset          Dataset   \n",
       "2  Intelligence, Security and the State: Reviewin...             Book   \n",
       "3  “A Spy Thriller Outdoes Fiction”: Popular Cult...  Journal article   \n",
       "\n",
       "                                 Link to publication  \\\n",
       "0  https://jjoas.com.ng/2024/01/25/from-global-to...   \n",
       "1                https://zenodo.org/records/13325699   \n",
       "2  https://edinburghuniversitypress.com/book-inte...   \n",
       "3  https://www.tandfonline.com/doi/abs/10.1080/14...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0                                        No abstract   \n",
       "1  This dataset contains metadata of publications...   \n",
       "2  The modern-day UK intelligence and security co...   \n",
       "3  Scholars are increasingly aware of the ways in...   \n",
       "\n",
       "                                         Zotero link  \\\n",
       "0  https://www.zotero.org/groups/intelligence_bib...   \n",
       "1  https://www.zotero.org/groups/intelligence_bib...   \n",
       "2  https://www.zotero.org/groups/intelligence_bib...   \n",
       "3  https://www.zotero.org/groups/intelligence_bib...   \n",
       "\n",
       "                 Date added Date published      Date modified  \\\n",
       "0 2024-08-16 00:11:00+00:00     25-01-2024  16/08/2024, 00:12   \n",
       "1 2024-08-15 11:06:38+00:00     15-08-2024  15/08/2024, 11:06   \n",
       "2 2024-08-14 21:02:35+00:00     01-03-2025  14/08/2024, 21:03   \n",
       "3 2024-08-14 21:01:32+00:00     13-08-2024  14/08/2024, 21:01   \n",
       "\n",
       "                Col key                                    Authors  \\\n",
       "0            [TLFN4NAL]                        Adebimpe S. Fagbemi   \n",
       "1            [CN9F5URY]                             Yusuf A. Ozkan   \n",
       "2            [CK5MNYPQ]  Daniel W. B. Lomas, Christopher J. Murphy   \n",
       "3  [CZT6L9T7, 9YH9YSYQ]                              Melanie Brand   \n",
       "\n",
       "                            Pub_venue Book_title   Thesis_type University  \\\n",
       "0  Jalingo Journal of African Studies       None  Unclassified              \n",
       "1                                None       None  Unclassified              \n",
       "2                                None       None  Unclassified              \n",
       "3       Journal of Australian Studies       None  Unclassified              \n",
       "\n",
       "          0         1  \n",
       "0  TLFN4NAL      None  \n",
       "1  CN9F5URY      None  \n",
       "2  CK5MNYPQ      None  \n",
       "3  CZT6L9T7  9YH9YSYQ  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_id = '2514686'\n",
    "library_type = 'group'\n",
    "api_key = '' # api_key is only needed for private groups and libraries\n",
    "\n",
    "zot = zotero.Zotero(library_id, library_type)\n",
    "def zotero_data(library_id, library_type):\n",
    "    items = zot.top(limit=5)\n",
    "    items = sorted(items, key=lambda x: x['data']['dateAdded'], reverse=True)\n",
    "    data=[]\n",
    "    columns = ['Title','Publication type', 'Link to publication', 'Abstract', 'Zotero link', 'Date added', 'Date published', 'Date modified', 'Col key', 'Authors', 'Pub_venue', 'Book_title', 'Thesis_type', 'University']\n",
    "\n",
    "    for item in items:\n",
    "        creators = item['data']['creators']\n",
    "        creators_str = \", \".join([\n",
    "            creator.get('firstName', '') + ' ' + creator.get('lastName', '')\n",
    "            if 'firstName' in creator and 'lastName' in creator\n",
    "            else creator.get('name', '') \n",
    "            for creator in creators\n",
    "        ])\n",
    "        data.append((item['data']['title'], \n",
    "        item['data']['itemType'], \n",
    "        item['data']['url'], \n",
    "        item['data']['abstractNote'], \n",
    "        item['links']['alternate']['href'],\n",
    "        item['data']['dateAdded'],\n",
    "        item['data'].get('date'), \n",
    "        item['data']['dateModified'],\n",
    "        item['data']['collections'],\n",
    "        creators_str,\n",
    "        item['data'].get('publicationTitle'),\n",
    "        item['data'].get('bookTitle'),\n",
    "        item['data'].get('thesisType', ''),\n",
    "        item['data'].get('university', '')\n",
    "        ))\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "df = zotero_data(library_id, library_type)\n",
    "df['Abstract'] = df['Abstract'].replace(r'^\\s*$', np.nan, regex=True) # To replace '' with NaN. Otherwise the code below do not understand the value is nan.\n",
    "df['Abstract'] = df['Abstract'].fillna('No abstract')\n",
    "\n",
    "split_df= pd.DataFrame(df['Col key'].tolist())\n",
    "df = pd.concat([df, split_df], axis=1)\n",
    "df['Authors'] = df['Authors'].fillna('null')  \n",
    "\n",
    "# Change type name\n",
    "type_map = {\n",
    "    'thesis': 'Thesis',\n",
    "    'journalArticle': 'Journal article',\n",
    "    'book': 'Book',\n",
    "    'bookSection': 'Book chapter',\n",
    "    'blogPost': 'Blog post',\n",
    "    'videoRecording': 'Video',\n",
    "    'podcast': 'Podcast',\n",
    "    'magazineArticle': 'Magazine article',\n",
    "    'webpage': 'Webpage',\n",
    "    'newspaperArticle': 'Newspaper article',\n",
    "    'report': 'Report',\n",
    "    'forumPost': 'Forum post',\n",
    "    'conferencePaper' : 'Conference paper',\n",
    "    'audioRecording' : 'Podcast',\n",
    "    'preprint':'Preprint',\n",
    "    'document':'Document',\n",
    "    'computerProgram':'Computer program',\n",
    "    'dataset':'Dataset'\n",
    "}\n",
    "\n",
    "mapping_thesis_type ={\n",
    "    \"MA Thesis\": \"Master's Thesis\",\n",
    "    \"PhD Thesis\": \"PhD Thesis\",\n",
    "    \"Master Thesis\": \"Master's Thesis\",\n",
    "    \"Thesis\": \"Master's Thesis\",  # Assuming 'Thesis' refers to Master's Thesis here, adjust if necessary\n",
    "    \"Ph.D.\": \"PhD Thesis\",\n",
    "    \"Master's Dissertation\": \"Master's Thesis\",\n",
    "    \"Undergraduate Theses\": \"Undergraduate Thesis\",\n",
    "    \"MPhil\": \"MPhil Thesis\",\n",
    "    \"A.L.M.\": \"Master's Thesis\",  # Assuming A.L.M. (Master of Liberal Arts) maps to Master's Thesis\n",
    "    \"doctoralThesis\": \"PhD Thesis\",\n",
    "    \"PhD\": \"PhD Thesis\",\n",
    "    \"Masters\": \"Master's Thesis\",\n",
    "    \"PhD thesis\": \"PhD Thesis\",\n",
    "    \"phd\": \"PhD Thesis\",\n",
    "    \"doctoral\": \"PhD Thesis\",\n",
    "    \"Doctoral\": \"PhD Thesis\",\n",
    "    \"Master of Arts Dissertation\": \"Master's Thesis\",\n",
    "    \"\":'Unclassified'\n",
    "}\n",
    "df['Thesis_type'] = df['Thesis_type'].replace(mapping_thesis_type)\n",
    "df['Publication type'] = df['Publication type'].replace(type_map)\n",
    "df['Date published'] = (\n",
    "    df['Date published']\n",
    "    .str.strip()\n",
    "    .apply(lambda x: pd.to_datetime(x, utc=True, errors='coerce').tz_convert('Europe/London'))\n",
    ")\n",
    "df['Date published'] = df['Date published'].dt.strftime('%d-%m-%Y')\n",
    "df['Date published'] = df['Date published'].fillna('No date')\n",
    "# df['Date published'] = df['Date published'].map(lambda x: x.strftime('%d/%m/%Y') if x else 'No date')\n",
    "\n",
    "# df['Date added'] = pd.to_datetime(df['Date added'], errors='coerce')\n",
    "# df['Date added'] = df['Date added'].dt.strftime('%d-%m-%Y')\n",
    "df['Date added'] = pd.to_datetime(df['Date added'], errors='coerce', utc=True)\n",
    "\n",
    "df['Date modified'] = pd.to_datetime(df['Date modified'], errors='coerce')\n",
    "df['Date modified'] = df['Date modified'].dt.strftime('%d/%m/%Y, %H:%M')\n",
    "\n",
    "today = datetime.now(pytz.UTC).date()\n",
    "days_ago = today - timedelta(days=3)\n",
    "\n",
    "df = df[df['Date added'].dt.date >= days_ago]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts without a link card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_mentions(text: str) -> List[Dict]:\n",
    "#     spans = []\n",
    "#     mention_regex = rb\"[$|\\W](@([a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\\.)+[a-zA-Z]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)\"\n",
    "#     text_bytes = text.encode(\"UTF-8\")\n",
    "#     for m in re.finditer(mention_regex, text_bytes):\n",
    "#         spans.append({\n",
    "#             \"start\": m.start(1),\n",
    "#             \"end\": m.end(1),\n",
    "#             \"handle\": m.group(1)[1:].decode(\"UTF-8\")\n",
    "#         })\n",
    "#     return spans\n",
    "\n",
    "# # Function to parse URLs from text\n",
    "# def parse_urls(text: str) -> List[Dict]:\n",
    "#     spans = []\n",
    "#     url_regex = rb\"[$|\\W](https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*[-a-zA-Z0-9@%_\\+~#//=])?)\"\n",
    "#     text_bytes = text.encode(\"UTF-8\")\n",
    "#     for m in re.finditer(url_regex, text_bytes):\n",
    "#         spans.append({\n",
    "#             \"start\": m.start(1),\n",
    "#             \"end\": m.end(1),\n",
    "#             \"url\": m.group(1).decode(\"UTF-8\"),\n",
    "#         })\n",
    "#     return spans\n",
    "\n",
    "# # Function to resolve handles to DIDs and create facets\n",
    "# def parse_facets(text: str) -> List[Dict]:\n",
    "#     facets = []\n",
    "#     for m in parse_mentions(text):\n",
    "#         resp = requests.get(\n",
    "#             \"https://bsky.social/xrpc/com.atproto.identity.resolveHandle\",\n",
    "#             params={\"handle\": m[\"handle\"]},\n",
    "#         )\n",
    "#         if resp.status_code == 400:\n",
    "#             continue\n",
    "#         did = resp.json()[\"did\"]\n",
    "#         facets.append({\n",
    "#             \"index\": {\n",
    "#                 \"byteStart\": m[\"start\"],\n",
    "#                 \"byteEnd\": m[\"end\"],\n",
    "#             },\n",
    "#             \"features\": [{\"$type\": \"app.bsky.richtext.facet#mention\", \"did\": did}],\n",
    "#         })\n",
    "#     for u in parse_urls(text):\n",
    "#         facets.append({\n",
    "#             \"index\": {\n",
    "#                 \"byteStart\": u[\"start\"],\n",
    "#                 \"byteEnd\": u[\"end\"],\n",
    "#             },\n",
    "#             \"features\": [\n",
    "#                 {\n",
    "#                     \"$type\": \"app.bsky.richtext.facet#link\",\n",
    "#                     \"uri\": u[\"url\"],\n",
    "#                 }\n",
    "#             ],\n",
    "#         })\n",
    "#     return facets\n",
    "\n",
    "# def truncate_text(text: str, max_length: int) -> str:\n",
    "#     if len(text) <= max_length:\n",
    "#         return text\n",
    "#     else:\n",
    "#         return text[:max_length-3] + \"...\"  # Reserve space for the ellipsis\n",
    "\n",
    "# # Iterate through the dataframe and create posts with hyperlinks\n",
    "# for index, row in df.iterrows():\n",
    "#     publication_type = row['Publication type']\n",
    "#     title = row['Title']\n",
    "#     link = row['Link to publication']\n",
    "#     publication_date = row['Date published']\n",
    "\n",
    "#     # Add the publication type at the beginning of the title\n",
    "#     post_text = f\"{publication_type}: {title} (published {publication_date})\\n\\n{link}\"\n",
    "\n",
    "#     # Check if the post text exceeds 300 characters\n",
    "#     if len(post_text) > 300:\n",
    "#         # Calculate the maximum length the title can be\n",
    "#         max_title_length = 300 - len(f\"{publication_type}: \\n{link}\")\n",
    "#         # Truncate the title to fit within the 300 character limit\n",
    "#         truncated_title = truncate_text(title, max_title_length)\n",
    "#         post_text = f\"{publication_type}: {truncated_title} (published {publication_date})\\n\\n{link}\"\n",
    "\n",
    "#     # Parse facets (mentions and links)\n",
    "#     facets = parse_facets(post_text)\n",
    "\n",
    "#     # Create the post payload\n",
    "#     post_payload = {\n",
    "#         \"$type\": \"app.bsky.feed.post\",\n",
    "#         \"text\": post_text,\n",
    "#         \"facets\": facets,\n",
    "#         \"createdAt\": pd.Timestamp.utcnow().isoformat() + \"Z\"\n",
    "#     }\n",
    "\n",
    "#     # Send the post to Bluesky\n",
    "#     post = client.send_post(\n",
    "#         text=post_payload[\"text\"],  # Pass only the text content\n",
    "#         facets=post_payload[\"facets\"],  # Pass facets separately\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts with link card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_link_metadata(url: str) -> Dict:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    title = soup.find(\"meta\", property=\"og:title\")\n",
    "    description = soup.find(\"meta\", property=\"og:description\")\n",
    "    image = soup.find(\"meta\", property=\"og:image\")\n",
    "\n",
    "    metadata = {\n",
    "        \"title\": title[\"content\"] if title else \"\",\n",
    "        \"description\": description[\"content\"] if description else \"\",\n",
    "        \"image\": image[\"content\"] if image else \"\",\n",
    "        \"url\": url,\n",
    "    }\n",
    "    return metadata\n",
    "\n",
    "def upload_image_to_bluesky(client, image_url: str) -> str:\n",
    "    response = requests.get(image_url)\n",
    "    # Assuming the client.upload_blob only needs the image content\n",
    "    image_blob = client.upload_blob(response.content)\n",
    "    return image_blob['blob']  # Assuming `blob` is the key where the blob reference is stored\n",
    "\n",
    "\n",
    "def create_link_card_embed(client, url: str) -> Dict:\n",
    "    metadata = fetch_link_metadata(url)\n",
    "    \n",
    "    # Check if the image URL is valid\n",
    "    if metadata[\"image\"]:\n",
    "        try:\n",
    "            image_blob = upload_image_to_bluesky(client, metadata[\"image\"])\n",
    "        except requests.exceptions.MissingSchema:\n",
    "            print(f\"Invalid image URL: {metadata['image']}\")\n",
    "            image_blob = None\n",
    "    else:\n",
    "        image_blob = None\n",
    "\n",
    "    embed = {\n",
    "        '$type': 'app.bsky.embed.external',\n",
    "        'external': {\n",
    "            'uri': metadata['url'],\n",
    "            'title': metadata['title'],\n",
    "            'description': metadata['description'],\n",
    "            'thumb': image_blob,  # This can be None if the image was invalid\n",
    "        },\n",
    "    }\n",
    "    return embed\n",
    "\n",
    "def parse_mentions(text: str) -> List[Dict]:\n",
    "    spans = []\n",
    "    mention_regex = rb\"[$|\\W](@([a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\\.)+[a-zA-Z]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)\"\n",
    "    text_bytes = text.encode(\"UTF-8\")\n",
    "    for m in re.finditer(mention_regex, text_bytes):\n",
    "        spans.append({\n",
    "            \"start\": m.start(1),\n",
    "            \"end\": m.end(1),\n",
    "            \"handle\": m.group(1)[1:].decode(\"UTF-8\")\n",
    "        })\n",
    "    return spans\n",
    "\n",
    "def parse_urls(text: str) -> List[Dict]:\n",
    "    spans = []\n",
    "    url_regex = rb\"[$|\\W](https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*[-a-zA-Z0-9@%_\\+~#//=])?)\"\n",
    "    text_bytes = text.encode(\"UTF-8\")\n",
    "    for m in re.finditer(url_regex, text_bytes):\n",
    "        spans.append({\n",
    "            \"start\": m.start(1),\n",
    "            \"end\": m.end(1),\n",
    "            \"url\": m.group(1).decode(\"UTF-8\"),\n",
    "        })\n",
    "    return spans\n",
    "\n",
    "def parse_facets(text: str) -> List[Dict]:\n",
    "    facets = []\n",
    "    for m in parse_mentions(text):\n",
    "        resp = requests.get(\n",
    "            \"https://bsky.social/xrpc/com.atproto.identity.resolveHandle\",\n",
    "            params={\"handle\": m[\"handle\"]},\n",
    "        )\n",
    "        if resp.status_code == 400:\n",
    "            continue\n",
    "        did = resp.json()[\"did\"]\n",
    "        facets.append({\n",
    "            \"index\": {\n",
    "                \"byteStart\": m[\"start\"],\n",
    "                \"byteEnd\": m[\"end\"],\n",
    "            },\n",
    "            \"features\": [{\"$type\": \"app.bsky.richtext.facet#mention\", \"did\": did}],\n",
    "        })\n",
    "    for u in parse_urls(text):\n",
    "        facets.append({\n",
    "            \"index\": {\n",
    "                \"byteStart\": u[\"start\"],\n",
    "                \"byteEnd\": u[\"end\"],\n",
    "            },\n",
    "            \"features\": [\n",
    "                {\n",
    "                    \"$type\": \"app.bsky.richtext.facet#link\",\n",
    "                    \"uri\": u[\"url\"],\n",
    "                }\n",
    "            ],\n",
    "        })\n",
    "    return facets\n",
    "\n",
    "def parse_facets_and_embed(text: str, client) -> Dict:\n",
    "    facets = parse_facets(text)\n",
    "    embed = None\n",
    "\n",
    "    for facet in facets:\n",
    "        if 'features' in facet and facet['features'][0]['$type'] == 'app.bsky.richtext.facet#link':\n",
    "            url = facet['features'][0]['uri']\n",
    "            embed = create_link_card_embed(client, url)\n",
    "            break  # Only handle the first link\n",
    "\n",
    "    return {\n",
    "        'facets': facets,\n",
    "        'embed': embed,\n",
    "    }\n",
    "\n",
    "def truncate_text(text: str, max_length: int) -> str:\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    else:\n",
    "        return text[:max_length-3] + \"...\"  # Reserve space for the ellipsis\n",
    "\n",
    "# Iterate through the dataframe and create posts with link cards\n",
    "for index, row in df.iterrows():\n",
    "    publication_type = row['Publication type']\n",
    "    title = row['Title']\n",
    "    publication_date = row['Date published']  # Extract the publication date\n",
    "    link = row['Link to publication']\n",
    "\n",
    "    post_text = f\"{publication_type}: {title} ({publication_date})\\n\\n{link}\"\n",
    "\n",
    "    if len(post_text) > 300:\n",
    "        max_title_length = 300 - len(f\"{publication_type}: \\n{link}\") - len(f\" ({publication_date})\")\n",
    "        truncated_title = truncate_text(title, max_title_length)\n",
    "        post_text = f\"{publication_type}: {truncated_title} (published {publication_date})\\n{link}\"\n",
    "\n",
    "    parsed = parse_facets_and_embed(post_text, client)\n",
    "    \n",
    "    post_payload = {\n",
    "        \"$type\": \"app.bsky.feed.post\",\n",
    "        \"text\": post_text,\n",
    "        \"facets\": parsed['facets'],\n",
    "        \"embed\": parsed['embed'],  # Include the embed if present\n",
    "        \"createdAt\": pd.Timestamp.utcnow().isoformat() + \"Z\"\n",
    "    }\n",
    "\n",
    "    post = client.send_post(\n",
    "        text=post_payload[\"text\"],  \n",
    "        facets=post_payload[\"facets\"],  \n",
    "        embed=post_payload.get(\"embed\"),  # Pass the embed if it exists\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
