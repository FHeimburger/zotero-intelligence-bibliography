{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyzotero import zotero\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import json, sys\n",
    "from datetime import date, timedelta  \n",
    "import datetime\n",
    "import plotly.express as px\n",
    "import pycountry\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_id = '2514686'\n",
    "library_type = 'group'\n",
    "api_key = '' # api_key is only needed for private groups and libraries\n",
    "zot = zotero.Zotero(library_id, library_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All items in the Zotero Intelligence bibliography library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = zot.everything(zot.top())\n",
    "\n",
    "data3=[]\n",
    "columns3=['Title','Publication type', 'Link to publication', 'Abstract', 'Zotero link', 'Date published', 'FirstName2', 'Publisher', 'Journal']\n",
    "\n",
    "for item in items:\n",
    "    data3.append((\n",
    "        item['data']['title'], \n",
    "        item['data']['itemType'], \n",
    "        item['data']['url'], \n",
    "        item['data']['abstractNote'], \n",
    "        item['links']['alternate']['href'],\n",
    "        item['data'].get('date'),\n",
    "        item['data']['creators'],\n",
    "        item['data'].get('publisher'),\n",
    "        item['data'].get('publicationTitle')\n",
    "        )) \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.DataFrame(data3, columns=columns3)\n",
    "\n",
    "mapping_types = {\n",
    "    'thesis': 'Thesis',\n",
    "    'journalArticle': 'Journal article',\n",
    "    'book': 'Book',\n",
    "    'bookSection': 'Book chapter',\n",
    "    'blogPost': 'Blog post',\n",
    "    'videoRecording': 'Video',\n",
    "    'podcast': 'Podcast',\n",
    "    'magazineArticle': 'Magazine article',\n",
    "    'webpage': 'Webpage',\n",
    "    'newspaperArticle': 'Newspaper article',\n",
    "    'report': 'Report',\n",
    "    'forumPost': 'Forum post',\n",
    "    'manuscript': 'Manuscript',\n",
    "    'document': 'Document',\n",
    "    'conferencePaper': 'Conference paper',\n",
    "    'film': 'Film',\n",
    "    'presentation': 'Presentation'\n",
    "}\n",
    "df['Publication type'] = df['Publication type'].replace(mapping_types)\n",
    "\n",
    "mapping_publisher = {\n",
    "    'Taylor & Francis Group': 'Taylor and Francis',\n",
    "    'Taylor and Francis': 'Taylor and Francis',\n",
    "    'Taylor & Francis': 'Taylor and Francis',\n",
    "    'Routledge': 'Routledge',\n",
    "    'Routledge Handbooks Online': 'Routledge',\n",
    "    'Praeger Security International': 'Praeger',\n",
    "    'Praeger': 'Praeger'\n",
    "}\n",
    "df['Publisher'] = df['Publisher'].replace(mapping_publisher)\n",
    "\n",
    "# df['Publisher'] = df['Publisher'].replace(['Taylor & Francis Group', 'Taylor and Francis', 'Taylor & Francis'], 'Taylor and Francis')\n",
    "# df['Publisher'] = df['Publisher'].replace(['Routledge', 'Routledge Handbooks Online'], 'Routledge')\n",
    "# df['Publisher'] = df['Publisher'].replace(['Praeger Security International', 'Praeger'], 'Praeger')\n",
    "\n",
    "mapping_journal = {\n",
    "    'International Journal of Intelligence and Counterintelligence': 'Intl Journal of Intelligence and Counterintelligence',\n",
    "    'International Journal of Intelligence and CounterIntelligence': 'Intl Journal of Intelligence and Counterintelligence',\n",
    "    'Intelligence and national security': 'Intelligence and National Security',\n",
    "    'Intelligence and National Security': 'Intelligence and National Security',\n",
    "    'Intelligence & National Security': 'Intelligence and National Security'\n",
    "}\n",
    "\n",
    "df['Journal'] = df['Journal'].replace(mapping_journal)\n",
    "\n",
    "# df['Journal'] = df['Journal'].replace(['International Journal of Intelligence and Counterintelligence', 'International Journal of Intelligence and CounterIntelligence'], 'Intl Journal of Intelligence and Counterintelligence')\n",
    "# df['Journal'] = df['Journal'].replace(['Intelligence and national security', 'Intelligence and National Security', 'Intelligence & National Security'], 'Intelligence and National Security')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_allitems = datetime.date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fa = df['FirstName2']\n",
    "df_fa = pd.DataFrame(df_fa.tolist())\n",
    "df_fa = df_fa[0]\n",
    "df_fa = df_fa.apply(lambda x: {} if pd.isna(x) else x)\n",
    "df_new = pd.json_normalize(df_fa, errors='ignore') \n",
    "df = pd.concat([df, df_new], axis=1)\n",
    "df['firstName'] = df['firstName'].fillna('null')\n",
    "df['lastName'] = df['lastName'].fillna('null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the csv file into a pandas dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YusufAliOzkan/zotero-intelligence-bibliography/main/all_items.csv')\n",
    "\n",
    "# Dictionary to map non-proper country names to their proper names\n",
    "country_map = {\n",
    "    'british': 'UK',\n",
    "    'great britain': 'UK',\n",
    "    'UK' : 'UK', \n",
    "    'america' : 'United States',\n",
    "    'United States of America' : 'United States',\n",
    "    'Soviet Union': 'Russia', \n",
    "    'american' : 'United States',\n",
    "    'United States' : 'United States',\n",
    "    'russian' : 'Russia'\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# Find the country names in the \"title\" column of the dataframe\n",
    "found_countries = {}\n",
    "for i, row in df.iterrows():\n",
    "    title = str(row['Title']).lower()\n",
    "    for country in pycountry.countries:\n",
    "        name = country.name.lower()\n",
    "        if name in title or (name + 's') in title:  # Check for singular and plural forms of country names\n",
    "            proper_name = country.name\n",
    "            found_countries[proper_name] = found_countries.get(proper_name, 0) + 1\n",
    "    for non_proper, proper in country_map.items():\n",
    "        if non_proper in title:\n",
    "            found_countries[proper] = found_countries.get(proper, 0) + title.count(non_proper)\n",
    "\n",
    "# Create a new dataframe containing the found countries and their counts\n",
    "df_countries = pd.DataFrame({'Country': list(found_countries.keys()), 'Count': list(found_countries.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(df_countries, locations='Country', locationmode='country names', color='Count', \n",
    "                    title='Country mentions in titles', color_continuous_scale='Viridis',\n",
    "                    width=1100, height=700) # Adjust the size of the map here\n",
    "\n",
    "# Display the map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries=df_countries.sort_values(by='Count', ascending=False)\n",
    "df_countries.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries.to_csv('countries.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad80e88e3d0f45253c4e09d27534efe22e9bb02b1c82d05b21d80e484bb90b14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
